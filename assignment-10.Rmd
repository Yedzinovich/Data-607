---
title: "Assignment 10"
author: Inna Yedzinovich
date: "`r Sys.Date()`"
---

```{r}
# Example code from "Text Mining with R", Chapter 2
# Citation: Silge, J., & Robinson, D. (2017). Text Mining with R: A Tidy Approach. O'Reilly Media.

# What are the most common joy words in Emma? 
library(janeaustenr)
library(dplyr)
library(stringr)
library(tidytext)
library(textdata)
library(tidyr)
library(ggplot2)

tidy_books <- austen_books() %>%
  group_by(book) %>%
  mutate(
    linenumber = row_number(),
    chapter = cumsum(str_detect(text, 
                                regex("^chapter [\\divxlc]", 
                                      ignore_case = TRUE)))) %>%
  ungroup() %>%
  unnest_tokens(word, text)

head(tidy_books)

# Now that the text is in a tidy format with one word per row, we are ready to do the sentiment analysis. First, let’s use the NRC lexicon and filter() for the joy words. Next, let’s filter() the data frame with the text from the books for the words from Emma and then use inner_join() to perform the sentiment analysis.

nrc_joy <- get_sentiments("nrc") %>% 
  filter(sentiment == "joy")
nrc_joy

tidy_books %>%
  filter(book == "Emma") %>%
  inner_join(nrc_joy) %>%
  count(word, sort = TRUE)
head(tidy_books)

# We then use pivot_wider() so that we have negative and positive sentiment in separate columns, and lastly calculate a net sentiment (positive - negative)

jane_austen_sentiment <- tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(book, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% 
  mutate(sentiment = positive - negative)

head(jane_austen_sentiment)

# Now we can plot these sentiment scores across the plot trajectory of each novel.

ggplot(jane_austen_sentiment, aes(index, sentiment, fill = book)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~book, ncol = 2, scales = "free_x")
```

Comparing the three sentiment dictionaries : 

``` {r }
# Now filter Pride & Prejudice book

pride_prejudice <- tidy_books %>% 
  filter(book == "Pride & Prejudice")

head(pride_prejudice)

# Now create a net sentiment for each part of the book using each of the lexicons

afinn <- pride_prejudice %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(index = linenumber %/% 80) %>% 
  summarise(sentiment = sum(value)) %>% 
  mutate(method = "AFINN")
head(afinn)

bing_and_nrc <- bind_rows(
  pride_prejudice %>% 
    inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing et al."),
  pride_prejudice %>% 
    inner_join(get_sentiments("nrc") %>% 
                 filter(sentiment %in% c("positive", 
                                         "negative"))
    ) %>%
    mutate(method = "NRC")) %>%
  count(method, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment,
              values_from = n,
              values_fill = 0) %>% 
  mutate(sentiment = positive - negative)
head(bing_and_nrc)

# Plot net sentiment:

bind_rows(afinn, 
          bing_and_nrc) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")


# Let’s look briefly at how many positive and negative words are in these lexicons.
get_sentiments("nrc") %>% 
  filter(sentiment %in% c("positive", "negative")) %>% 
  count(sentiment)

get_sentiments("bing") %>% 
  count(sentiment)

```

Most common positive and negative words: 

``` {r }
bing_word_counts <- tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

head(bing_word_counts)

bing_word_counts %>%
  group_by(sentiment) %>%
  slice_max(n, n = 10) %>% 
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(x = "Contribution to sentiment",
       y = NULL)

# Now add word “miss” to custom words:

custom_stop_words <- bind_rows(tibble(word = c("miss"),  
                                      lexicon = c("custom")), 
                               stop_words)

head(custom_stop_words)
```

Wordclouds: 

``` {r}
library(wordcloud)

tidy_books %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100))

library(reshape2)

tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("gray20", "gray80"),
                   max.words = 100)
```

Looking at units beyond just words: 

``` {r }
p_and_p_sentences <- tibble(text = prideprejudice) %>% 
  unnest_tokens(sentence, text, token = "sentences")
head(p_and_p_sentences)

p_and_p_sentences$sentence[2]

austen_chapters <- austen_books() %>%
  group_by(book) %>%
  unnest_tokens(chapter, text, token = "regex", 
                pattern = "Chapter|CHAPTER [\\dIVXLC]") %>%
  ungroup()

head(austen_chapters)

austen_chapters %>% 
  group_by(book) %>% 
  summarise(chapters = n())
head(austen_chapters)

bingnegative <- get_sentiments("bing") %>% 
  filter(sentiment == "negative")
head(bingnegative)

wordcounts <- tidy_books %>%
  group_by(book, chapter) %>%
  summarize(words = n())
head(wordcounts)

tidy_books %>%
  semi_join(bingnegative) %>%
  group_by(book, chapter) %>%
  summarize(negativewords = n()) %>%
  left_join(wordcounts, by = c("book", "chapter")) %>%
  mutate(ratio = negativewords/words) %>%
  filter(chapter != 0) %>%
  slice_max(ratio, n = 1) %>% 
  ungroup()
head(tidy_books)
```

Now, let’s use the gutenbergr library to analyze another book, “Moby Dick” by Herman Melville using similar approach.

``` {r }
library(gutenbergr)

moby_dick <- gutenberg_download(2701, mirror = "http://www.gutenberg.lib.md.us/")
head(moby_dick)

tidy_moby_dick <- moby_dick %>%
  mutate(text = str_replace_all(text, "[^[:alnum:][:space:]]", "")) %>%
  unnest_tokens(word, text)
head(tidy_moby_dick)

# Perform sentiment analysis:
# Using NRC lexicon for joy words
nrc_joy <- get_sentiments("nrc") %>% 
  filter(sentiment == "joy")

tidy_moby_dick %>%
  inner_join(nrc_joy) %>%
  count(word, sort = TRUE)

moby_dick_sentiment <- tidy_moby_dick %>%
  inner_join(get_sentiments("bing")) %>%
  count(index = row_number() %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
  mutate(sentiment = positive - negative)
head(moby_dick_sentiment)

ggplot(moby_dick_sentiment, aes(index, sentiment)) +
  geom_col(show.legend = FALSE) +
  labs(title = "Sentiment Analysis of Moby Dick",
       x = "Index",
       y = "Sentiment Score")

# Compare sentiment dictionaries:

# AFINN lexicon
afinn <- tidy_moby_dick %>%
  inner_join(get_sentiments("afinn")) %>%
  group_by(index = row_number() %/% 80) %>%
  summarise(sentiment = sum(value)) %>%
  mutate(method = "AFINN")

# Bing and NRC lexicons
bing_and_nrc <- bind_rows(
  tidy_moby_dick %>%
    inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing et al."),
  tidy_moby_dick %>%
    inner_join(get_sentiments("nrc") %>% 
                 filter(sentiment %in% c("positive", "negative"))) %>%
    mutate(method = "NRC")) %>%
  count(method, index = row_number() %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
  mutate(sentiment = positive - negative)

bind_rows(afinn, bing_and_nrc) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y") +
  labs(title = "Sentiment Analysis Comparison for Moby Dick",
       x = "Index",
       y = "Sentiment Score")

```

Now, Let’s use the sentimentr package to perform sentiment analysis on “Moby Dick”: 

``` {r }
library(sentimentr)

library(gutenbergr)
moby_dick <- gutenberg_download(2701, mirror = "http://www.gutenberg.lib.md.us/")
head(moby_dick)

# prepare the text data:
tidy_moby_dick <- moby_dick %>%
  mutate(text = str_replace_all(text, "[^[:alnum:][:space:]]", "")) %>%
  unnest_tokens(sentence, text, token = "sentences")
head(tidy_moby_dick)

# perform sentiment analysis using sentimentr:

# calculate sentiment for each sentence
sentiment_scores <- sentiment(tidy_moby_dick$sentence)

# add sentiment scores to the original data
tidy_moby_dick <- tidy_moby_dick %>%
  mutate(sentiment = sentiment_scores$sentiment)
head(tidy_moby_dick)

# aggregate sentiment scores by index
moby_dick_sentiment <- tidy_moby_dick %>%
  mutate(index = row_number() %/% 80) %>%
  group_by(index) %>%
  summarise(sentiment = sum(sentiment))
head(moby_dick_sentiment)

ggplot(moby_dick_sentiment, aes(index, sentiment)) +
  geom_col(show.legend = FALSE) +
  labs(title = "Sentiment Analysis of Moby Dick",
       x = "Index",
       y = "Sentiment Score")

```

Conclusion: 

This follwing graph shows the emotional ups and downs in Moby Dick: 

 - Big Swings: The emotions change a lot, with some parts feeling positive and others negative, creating a rollercoaster of feelings.
 - Mostly Negative: There are more dips into negative emotions, which makes sense since Moby Dick is a story with dark themes, like revenge and obsession.
 - Some Calm Sections: Many points are close to zero, which might be more neutral parts of the story where things aren’t very emotional.
 - Positive Moments: There are a few spots with higher, positive emotions, possibly showing lighter moments in the story, like friendship or breaks in the action.

Overall, the emotional tone of Moby Dick swings between positive and negative, with more leaning toward the negative side.

